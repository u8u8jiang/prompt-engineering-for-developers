# 简介

**吴恩达教授, Isa Fulford 教授**        
Isa Fulford 是 OpenAI 的技術團隊成員，曾開發過受歡迎的 ChatGPT 檢索插件，並且在教學人們如何在産品中使用 LLM 或 LLM 技術方面做出了很大貢獻。她還參與編寫了教授人們使用 Prompt 的 OpenAI cookbook。

* 為開發人員介紹 ChatGPT 提示工程, 透過調用LLM API, 指令調整 LLM 快速建構應用程序        
* 隨著大型語言模型（LLM）的發展，LLM 大致可以分爲兩種類型，即基礎LLM和指令微調LLM。基礎LLM是基於文本訓練數據，訓練出預測下一個單詞能力的模型，其通常是在互聯網和其他來源的大量數據上訓練的。


例如，如果你以“從前有一隻獨角獸”作爲提示，
* 基礎LLM可能會繼續預測“生活在一個與所有獨角獸朋友的神奇森林中”。但是，如果你以“法國的首都是什麽”爲提示，則基礎LLM可能會根據互聯網上的文章，將答案預測爲“法國最大的城市是什麽？法國的人口是多少？”，因爲互聯網上的文章很可能是有關法國國家的問答題目列表。              
* 許多 LLMs 的研究和實踐的動力正在指令調整的 LLMs 上。指令調整的 LLMs 已經被訓練來遵循指令。因此，如果你問它，“法國的首都是什麽？”，它更有可能輸出“法國的首都是巴黎”。          

指令調整的 LLMs 的訓練通常是從已經訓練好的基本 LLMs 開始，該模型已經在大量文本上進行了訓練。        
使用輸入是指令、輸出是其應該返回的結果的數據集來對其進行微調，要求它遵循這些指令。使用一種稱爲 RLHF（reinforcement learning from human feedback，人類反饋强化學習）的技術進行改進，使系統更能够有幫助地遵循指令。                   
因爲指令調整的 LLMs 已經被訓練成有益、誠實和無害的，與基礎LLMs相比，較不會輸出有問題的文本，指令調整的LLMs更容易使用，而且由於OpenAI和其他LLM公司的工作，它們變得更加安全和更加協調。    

       
感謝 OpenAI 和 DeepLearning.ai 團隊         
OpenAI 的 Andrew Main、Joe Palermo、Boris Power、Ted Sanders 和 Lillian Weng，
Deep Learning 方面的 Geoff Ladwig、Eddy Shyu 和 Tommy Nelson.           

當您使用指令調整 LLM 時，請假設它是一個聰明但不知道您任務的具體細節的人。當 LLM 無法正常工作時，有時是因爲指令不够清晰。例如，如果您說“請爲我寫一些關于阿蘭·圖靈的東西”，清楚表明您希望文本專注于他的科學工作、個人生活、歷史角色或其他方面可能會更有幫助。更多的，您還可以指定文本采取像專業記者寫作的語調，或者更像是您向朋友寫的隨筆。
下一章你會看到如何讓提示清晰明確，創建提示的一個重要原則，你還會從提示的第二個原則中學到給LLM時間去思考。               


